# Introduction to Simple Linear Regressions (Video)

https://www.youtube.com/watch?v=KsVBBJRb9TE

>"Regressions analysis explores the relationship between a quantitative response variable and one or more explanatory variables."

There might be an easier and a more difficult piece of data to quantify. In the video, density is much easier to find, so that will be the explanatory variable while finding the hardness will be the response(dependent) variable. We are trying to use density to predict hardness.

# How to run Linear regression in Python scikit-Learn

**NOTE: Since this demo was published scikit-learn has been updated. The train_test_split function is now imported from sklearn.model_selection**

https://bigdata-madesimple.com/how-to-run-linear-regression-in-python-scikit-learn/

sckit-learn - python module for machine learning

from article:
>"Important functions to keep in mind while fitting a linear regression model are:
> - .fit() -> fits a linear model
> - .predict() -> Predict Y using the linear model with estimated coefficients
> - .score() -> Returns the coefficient of determination (R^2). A measure of how well observed outcomes are replicated by the model, as the proportion of total variation of outcomes explained by the model."

# What is Linear Regression?

https://www.statisticssolutions.com/free-resources/directory-of-statistical-analyses/what-is-linear-regression/

From this article:

> "Linear regression is a basic and commonly used type of predictive analysis.  The overall idea of regression is to examine two things: (1) does a set of predictor variables do a good job in predicting an outcome (dependent) variable?  (2) Which variables in particular are significant predictors of the outcome variable, and in what way do they–indicated by the magnitude and sign of the beta estimates–impact the outcome variable?  These regression estimates are used to explain the relationship between one dependent variable and one or more independent variables.  The simplest form of the regression equation with one dependent and one independent variable is defined by the formula y = c + b*x, where y = estimated dependent variable score, c = constant, b = regression coefficient, and x = score on the independent variable.

Naming the Variables.  There are many names for a regression’s dependent variable.  It may be called an outcome variable, criterion variable, endogenous variable, or regressand.  The independent variables can be called exogenous variables, predictor variables, or regressors.

Three major uses for regression analysis are (1) determining the strength of predictors, (2) forecasting an effect, and (3) trend forecasting."

> "Types of Linear Regression
> 1. Simple linear regression
1 dependent variable (interval or ratio), 1 independent variable (interval or ratio or dichotomous)
>2. Multiple linear regression
1 dependent variable (interval or ratio) , 2+ independent variables (interval or ratio or dichotomous)
> 3. Logistic regression
1 dependent variable (dichotomous), 2+ independent variable(s) (interval or ratio or dichotomous)
> 4. Ordinal regression
1 dependent variable (ordinal), 1+ independent variable(s) (nominal or dichotomous)
> 5. Multinomial regression
1 dependent variable (nominal), 1+ independent variable(s) (interval or ratio or dichotomous)
> 6. Discriminant analysis
1 dependent variable (nominal), 1+ independent variable(s) (interval or ratio)"

# Scikit-Learn Cheat Sheet (2021), Python for Data Science
### The absolute basics for beginners learning Scikit-Learn in 2021

https://towardsdatascience.com/scikit-learn-cheat-sheet-2021-python-for-data-science-c634fd5dcbd0

# The Data Professor

https://www.youtube.com/watch?v=R15LjD8aCzc


[code401 Reading Notes](../401Python/code401Table.md)